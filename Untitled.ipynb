{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.3.0 pyspark-shell'\n",
    "\n",
    "from time import sleep\n",
    "from kafka import KafkaConsumer\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "# this line is needed for the inline display of graphs in Jupyter Notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "x, y, y2 = [], [], []\n",
    "def init_plots():\n",
    "    try:\n",
    "        width = 9.5\n",
    "        height = 6\n",
    "        fig = plt.figure(figsize=(width,height)) # create new figure\n",
    "        ax = fig.add_subplot(111) # adding the subplot axes to the given grid position\n",
    "        fig.suptitle('Real-time uniform stream data visualization') # giving figure a title\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.set_ylim(0,110) \n",
    "        ax.set_yticks([0,20,40,60,80,100])\n",
    "        fig.show() # displaying the figure\n",
    "        fig.canvas.draw() # drawing on the canvas\n",
    "        return fig, ax\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "    \n",
    "def consume_messages(consumer, fig, ax):\n",
    "    try:\n",
    "        # container for x and y values\n",
    "        global x\n",
    "        global y\n",
    "        global y2\n",
    "        # print('Waiting for messages')\n",
    "        for message in consumer.collect():\n",
    "            print('*'* 40)\n",
    "            print(message)\n",
    "            print('*'* 40)\n",
    "            data = message\n",
    "            #data = str(message.value.decode('utf-8')).split(', ')\n",
    "            x.append(data['created_at']) \n",
    "            y.append(min(y + [data['air_temperature_celcius']]))\n",
    "            y2.append(max(y + [data['air_temperature_celcius']]))\n",
    "            # print(y)\n",
    "            # we start plotting only when we have 10 data points\n",
    "        if len(y) >= 10:\n",
    "            ax.clear()\n",
    "            ax.plot(x, y)\n",
    "            ax.plot(x, y2)\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Value')\n",
    "            ax.set_ylim(0,80) \n",
    "            ax.set_yticks([0,20,40,60,80,100])\n",
    "            fig.canvas.draw()\n",
    "            x.pop(0) # removing the item in the first position\n",
    "            y.pop(0)\n",
    "            y2.pop(0)\n",
    "        #plt.close('all')\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    fig, ax = init_plots()\n",
    "    topic = ['climate']\n",
    "    n_secs = 1\n",
    "    conf = SparkConf().setAppName(\"KafkaStreamProcessor\")\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    if sc is None:\n",
    "        sc = SparkContext(conf=conf)\n",
    "    sc.setLogLevel(\"WARN\")\n",
    "    ssc = StreamingContext(sc, n_secs)\n",
    "    \n",
    "    kafkaStream = KafkaUtils.createDirectStream(ssc,topic , {\n",
    "            'bootstrap.servers':'localhost:9092', \n",
    "            })\n",
    "    lines = kafkaStream.map(lambda x: json.loads(x[1]))\n",
    "# lines.pprint()\n",
    "    fore = lines.foreachRDD(lambda x: consume_messages(x, fig, ax))\n",
    "    ssc.start()\n",
    "    ssc.awaitTermination()\n",
    "    \n",
    "#     consume_messages(consumer, fig, ax)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmplot\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.fit5148_db\n",
    "collection = db.week13\n",
    "items = collection.find({},{\"_id\":0})\n",
    "\n",
    "\n",
    "lats = []\n",
    "longs = []\n",
    "gmap = gmplot.GoogleMapPlotter(-37.452, 148.115, 16)\n",
    "for item in items:\n",
    "    for fire in item['Fire']:\n",
    "        lats.append(fire['latitude'])\n",
    "        longs.append(fire['longitude'])\n",
    "        gmap.marker(fire['latitude'], fire['longitude'],'cornflowerblue',\n",
    "                    title = 'air_temperature_celcius :'+ str(item['air_temperature_celcius']) + ' ' +\n",
    "                    'relative_humidity :' + str(item['relative_humidity']) + ' ' +\n",
    "                    'surface_temperature_celcius  :' + str(fire['surface_temperature_celcius']) + ' ' +\n",
    "                    'confidence :' + str(fire['confidence']))\n",
    "    \n",
    "\n",
    "gmap.draw(\"mymap.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
